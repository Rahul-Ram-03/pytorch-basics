{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCvLeW4jJ8bQ",
        "outputId": "cfa8fadb-fa2f-4bf0-f7c3-75f953622c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OBsNxELKPioI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torchvision.transforms import ToTensor, Resize\n",
        "import torch.nn as N\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv2\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W8ctJoncPioJ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 9e-3\n",
        "smooth = 1e-7\n",
        "\n",
        "filters = [64, 128, 256, 512]\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M1G7mLBgQ1PP"
      },
      "outputs": [],
      "source": [
        "transforms = [Resize((256,256))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pd2KZdAJ2aq",
        "outputId": "5e266136-78c4-4e76-99d6-40d1dddd26e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset OxfordIIITPet\n",
              "    Number of datapoints: 3680\n",
              "    Root location: ../pytorch-basics/datasets"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "OxfordIIITPet('../pytorch-basics/datasets', 'trainval', 'segmentation', download= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jqr_-QiEJ2ar"
      },
      "outputs": [],
      "source": [
        "class OxfordPetDataset(Dataset):\n",
        "    def __init__(self, split= 'trainval', transforms= []) -> None:\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.list_of_files = []\n",
        "        self.input_dir = '../pytorch-basics/datasets/oxford-iiit-pet/images/'\n",
        "        self.target_dir = '../pytorch-basics/datasets/oxford-iiit-pet/annotations/trimaps/'\n",
        "\n",
        "        if(split == 'trainval'):\n",
        "            file_list_path = '../pytorch-basics/datasets/oxford-iiit-pet/annotations/trainval.txt'\n",
        "        else:\n",
        "            file_list_path = '../pytorch-basics/datasets/oxford-iiit-pet/annotations/test.txt'\n",
        "\n",
        "        with open(file_list_path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                self.list_of_files.append(line.split(' ')[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.list_of_files))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_path = self.input_dir + self.list_of_files[index] + '.jpg'\n",
        "        target_path = self.target_dir + self.list_of_files[index] + '.png'\n",
        "\n",
        "        input = ToTensor()(cv2.imread(input_path))\n",
        "        target = torch.IntTensor(cv2.imread(target_path, flags= cv2.IMREAD_UNCHANGED))\n",
        "\n",
        "        if len(target.shape) == 2:\n",
        "            target = target[None, :, :]\n",
        "\n",
        "        for transform in self.transforms:\n",
        "            input = transform(input)\n",
        "            target = transform(target)\n",
        "\n",
        "        target -= 1\n",
        "        target = target.type(torch.int64)\n",
        "        target = N.functional.one_hot(target, num_classes)\n",
        "        target = target.squeeze().type(torch.float32).permute(2,0,1)\n",
        "\n",
        "        return (input, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rzmnaXa_PioK"
      },
      "outputs": [],
      "source": [
        "training_data = OxfordPetDataset('trainval', transforms= transforms)\n",
        "test_data = OxfordPetDataset('test', transforms= transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7KYaeLO1PioK"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size= batch_size, shuffle= True, drop_last= True)\n",
        "test_dataloader = DataLoader(test_data, batch_size= batch_size, shuffle= True, drop_last= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TiWhgTV6PioK"
      },
      "outputs": [],
      "source": [
        "class DownwardBlock(N.Module):\n",
        "    def __init__(self, in_channels, out_channels, device, stride= 1, kernel_size= 3, padding= 'same'):\n",
        "        super(DownwardBlock, self).__init__()\n",
        "\n",
        "        self.enc_block = N.Sequential(\n",
        "            N.Conv2d(in_channels, out_channels, kernel_size, stride, padding, device= device, bias= False),\n",
        "            N.BatchNorm2d(out_channels, device= device),\n",
        "            N.ReLU(inplace= True),\n",
        "\n",
        "            N.Conv2d(out_channels, out_channels, kernel_size, stride, padding, device= device, bias= False),\n",
        "            N.BatchNorm2d(out_channels, device= device),\n",
        "            N.ReLU(inplace= True)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.enc_block(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uMkxpHdNPioK"
      },
      "outputs": [],
      "source": [
        "class DownwardHalf(N.Module):\n",
        "    def __init__(self, filters, device):\n",
        "        super(DownwardHalf, self).__init__()\n",
        "        self.down_blocks = N.ModuleList()\n",
        "        self.mpool = N.MaxPool2d(kernel_size= 2, stride= 2)\n",
        "\n",
        "        for i in range(len(filters)):\n",
        "            if i == 0:\n",
        "                self.down_blocks.append(DownwardBlock(3, filters[i], device= device))\n",
        "            else:\n",
        "                self.down_blocks.append(DownwardBlock(filters[i-1], filters[i], device= device))\n",
        "\n",
        "    def forward(self, input):\n",
        "        skip_conn = []\n",
        "        for i in range(len(self.down_blocks)):\n",
        "            input = self.down_blocks[i](input)\n",
        "            skip_conn.append(input)\n",
        "            input = self.mpool(input)\n",
        "\n",
        "        return input, skip_conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U0SMIqB7PioL"
      },
      "outputs": [],
      "source": [
        "class UpwardBlock(N.Module):\n",
        "    def __init__(self, in_channels, out_channels, device, stride= 1, kernel_size= 3, padding='same'):\n",
        "        super(UpwardBlock, self).__init__()\n",
        "\n",
        "        self.tconv = N.ConvTranspose2d(in_channels, out_channels, kernel_size= 2, stride= 2, device= device)\n",
        "        self.dec_block = N.Sequential(\n",
        "            N.Conv2d(in_channels, out_channels, kernel_size, stride, padding, device= device, bias= False),\n",
        "            N.BatchNorm2d(out_channels, device= device),\n",
        "            N.ReLU(inplace= True),\n",
        "\n",
        "            N.Conv2d(out_channels, out_channels, kernel_size, stride, padding, device= device, bias= False),\n",
        "            N.BatchNorm2d(out_channels, device= device),\n",
        "            N.ReLU(inplace= True)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, skip_conn):\n",
        "        tconv_output = self.tconv(input)\n",
        "        concat_output = torch.cat([tconv_output, skip_conn], dim= 1)\n",
        "        output = self.dec_block(concat_output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vCtoI94UPioL"
      },
      "outputs": [],
      "source": [
        "class UpwardHalf(N.Module):\n",
        "    def __init__(self, filters, device):\n",
        "        super(UpwardHalf, self).__init__()\n",
        "        self.up_blocks = N.ModuleList()\n",
        "        n = len(filters)\n",
        "\n",
        "        for i in range(n):\n",
        "          self.up_blocks.append(UpwardBlock(filters[n-i-1] * 2, filters[n-i-1], device))\n",
        "\n",
        "    def forward(self, input, skip_conn):\n",
        "        n = len(self.up_blocks)\n",
        "        for i in range(n):\n",
        "            input = self.up_blocks[i](input, skip_conn[n-i-1])\n",
        "\n",
        "        return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jFcjzOHNZtsF"
      },
      "outputs": [],
      "source": [
        "class UNet(N.Module):\n",
        "    def __init__(self, filters, device):\n",
        "        super(UNet, self).__init__()\n",
        "        self.down_half = DownwardHalf(filters, device)\n",
        "        self.up_half = UpwardHalf(filters, device)\n",
        "        self.final_conv = N.Conv2d(filters[0], num_classes, 3, 1, 'same', device= device)\n",
        "        self.bridge_block = N.Sequential(\n",
        "            N.Conv2d(filters[-1], filters[-1] * 2, 3, 1, 'same', device= device, bias= False),\n",
        "            N.BatchNorm2d(filters[-1] * 2, device= device),\n",
        "            N.ReLU(inplace= True),\n",
        "\n",
        "            N.Conv2d(filters[-1] * 2, filters[-1] * 2, 3, 1, 'same', device= device, bias= False),\n",
        "            N.BatchNorm2d(filters[-1] * 2, device= device),\n",
        "            N.ReLU(inplace= True)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        down_half_output, skip_conn = self.down_half(input)\n",
        "        bridge_block_output = self.bridge_block(down_half_output)\n",
        "        up_half_output = self.up_half(bridge_block_output, skip_conn)\n",
        "        output = self.final_conv(up_half_output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTY-iyrzfbiy",
        "outputId": "aa4359ed-ccc1-45f0-dde0-f31aac8a7049"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type (var_name))                       Input Shape               Output Shape              Param #                   Trainable\n",
              "=================================================================================================================================================\n",
              "UNet (UNet)                                   [32, 3, 256, 256]         [32, 3, 256, 256]         --                        True\n",
              "├─DownwardHalf (down_half)                    [32, 3, 256, 256]         [32, 512, 16, 16]         --                        True\n",
              "│    └─ModuleList (down_blocks)               --                        --                        (recursive)               True\n",
              "│    │    └─DownwardBlock (0)                 [32, 3, 256, 256]         [32, 64, 256, 256]        38,848                    True\n",
              "│    └─MaxPool2d (mpool)                      [32, 64, 256, 256]        [32, 64, 128, 128]        --                        --\n",
              "│    └─ModuleList (down_blocks)               --                        --                        (recursive)               True\n",
              "│    │    └─DownwardBlock (1)                 [32, 64, 128, 128]        [32, 128, 128, 128]       221,696                   True\n",
              "│    └─MaxPool2d (mpool)                      [32, 128, 128, 128]       [32, 128, 64, 64]         --                        --\n",
              "│    └─ModuleList (down_blocks)               --                        --                        (recursive)               True\n",
              "│    │    └─DownwardBlock (2)                 [32, 128, 64, 64]         [32, 256, 64, 64]         885,760                   True\n",
              "│    └─MaxPool2d (mpool)                      [32, 256, 64, 64]         [32, 256, 32, 32]         --                        --\n",
              "│    └─ModuleList (down_blocks)               --                        --                        (recursive)               True\n",
              "│    │    └─DownwardBlock (3)                 [32, 256, 32, 32]         [32, 512, 32, 32]         3,540,992                 True\n",
              "│    └─MaxPool2d (mpool)                      [32, 512, 32, 32]         [32, 512, 16, 16]         --                        --\n",
              "├─Sequential (bridge_block)                   [32, 512, 16, 16]         [32, 1024, 16, 16]        --                        True\n",
              "│    └─Conv2d (0)                             [32, 512, 16, 16]         [32, 1024, 16, 16]        4,718,592                 True\n",
              "│    └─BatchNorm2d (1)                        [32, 1024, 16, 16]        [32, 1024, 16, 16]        2,048                     True\n",
              "│    └─ReLU (2)                               [32, 1024, 16, 16]        [32, 1024, 16, 16]        --                        --\n",
              "│    └─Conv2d (3)                             [32, 1024, 16, 16]        [32, 1024, 16, 16]        9,437,184                 True\n",
              "│    └─BatchNorm2d (4)                        [32, 1024, 16, 16]        [32, 1024, 16, 16]        2,048                     True\n",
              "│    └─ReLU (5)                               [32, 1024, 16, 16]        [32, 1024, 16, 16]        --                        --\n",
              "├─UpwardHalf (up_half)                        [32, 1024, 16, 16]        [32, 64, 256, 256]        --                        True\n",
              "│    └─ModuleList (up_blocks)                 --                        --                        --                        True\n",
              "│    │    └─UpwardBlock (0)                   [32, 1024, 16, 16]        [32, 512, 32, 32]         9,177,600                 True\n",
              "│    │    └─UpwardBlock (1)                   [32, 512, 32, 32]         [32, 256, 64, 64]         2,295,040                 True\n",
              "│    │    └─UpwardBlock (2)                   [32, 256, 64, 64]         [32, 128, 128, 128]       574,080                   True\n",
              "│    │    └─UpwardBlock (3)                   [32, 128, 128, 128]       [32, 64, 256, 256]        143,680                   True\n",
              "├─Conv2d (final_conv)                         [32, 64, 256, 256]        [32, 3, 256, 256]         1,731                     True\n",
              "=================================================================================================================================================\n",
              "Total params: 31,039,299\n",
              "Trainable params: 31,039,299\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (T): 1.75\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 25.17\n",
              "Forward/backward pass size (MB): 18438.16\n",
              "Params size (MB): 124.16\n",
              "Estimated Total Size (MB): 18587.48\n",
              "================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(filters, device)\n",
        "\n",
        "summary(model, input_size= (batch_size, 3, 256, 256), col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "\n",
        "        row_settings=['var_names'], verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(output, target):\n",
        "    output_flattened = output.flatten()\n",
        "    target_flattened = target.flatten()\n",
        "    intersection = torch.sum(output_flattened * target_flattened)\n",
        "\n",
        "    dice_score = (2. * intersection + smooth)/(torch.sum(output_flattened) + torch.sum(target_flattened) + smooth)\n",
        "    return dice_score\n",
        "\n",
        "def dice_score_multiclass(output, target, num_classes):\n",
        "    output = torch.argmax(output, dim= 1).type(torch.int64)\n",
        "    output = N.functional.one_hot(output, num_classes).permute(0,3,1,2)\n",
        "    target = target.type(torch.int64)\n",
        "\n",
        "    dice= 0\n",
        "    for idx in range(num_classes):\n",
        "        dice += dice_score(output[:,idx,:,:], target[:,idx,:,:])\n",
        "\n",
        "    return dice/num_classes"
      ],
      "metadata": {
        "id": "7GD7E1MvEi-G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "14oLqbuXtwdC"
      },
      "outputs": [],
      "source": [
        "loss_fn = N.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDWCaeh1ZNcn",
        "outputId": "ef2cc037-dbe5-4ec9-b0eb-8b1d5e7d7b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting epoch 1\n",
            "~~~~~~~~~~~~~~\n",
            "Batch: 0 Loss:1.105314374\n",
            "Batch: 50 Loss:0.822457671\n",
            "Batch: 100 Loss:0.808479190\n",
            "Train loss: 0.84978 Test loss: 0.82083 Test dice score: 0.26850\n",
            "\n",
            "Starting epoch 2\n",
            "~~~~~~~~~~~~~~\n",
            "Batch: 0 Loss:0.832635283\n",
            "Batch: 50 Loss:0.782255232\n",
            "Batch: 100 Loss:0.795452833\n",
            "Train loss: 0.80102 Test loss: 0.83191 Test dice score: 0.28930\n",
            "\n",
            "Starting epoch 3\n",
            "~~~~~~~~~~~~~~\n",
            "Batch: 0 Loss:0.794442296\n",
            "Batch: 50 Loss:0.808420539\n"
          ]
        }
      ],
      "source": [
        "for _ in range(epochs):\n",
        "    train_loss = 0\n",
        "    print(f\"\\nStarting epoch {_ + 1}\\n~~~~~~~~~~~~~~\")\n",
        "\n",
        "    for index, (input, target) in enumerate(train_dataloader):\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "        model.train()\n",
        "        output = model(input)\n",
        "        output = N.Softmax(dim= 1)(output)\n",
        "\n",
        "        loss = loss_fn(output, target)\n",
        "        train_loss += loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if(index % 50 == 0):\n",
        "            print(f\"Batch: {index} Loss:{loss:0.9f}\")\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    test_loss, test_dice = 0, 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for test_input, test_target in test_dataloader:\n",
        "            test_input, test_target = test_input.cuda(), test_target.cuda()\n",
        "\n",
        "            test_output = model(test_input)\n",
        "            test_output = N.Softmax(dim= 1)(test_output)\n",
        "            test_loss += loss_fn(test_output, test_target)\n",
        "            test_dice += dice_score_multiclass(test_target, test_output, num_classes)\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_dice /= len(test_dataloader)\n",
        "\n",
        "    print(f\"Train loss: {train_loss:0.5f} Test loss: {test_loss:0.5f} Test dice score: {test_dice:0.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index =  torch.randint(0, len(test_dataloader), size= (1,))\n",
        "sample_input, sample_target = next(itertools.islice(test_dataloader, sample_index, None))"
      ],
      "metadata": {
        "id": "jm2I4INRn9Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output = model(sample_input.cuda())"
      ],
      "metadata": {
        "id": "SOXCxblCY7i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output = torch.argmax(N.Softmax(dim= 1)(sample_output), dim= 1)"
      ],
      "metadata": {
        "id": "GENGXTb_d-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.randint(0, 32, size= (1,))\n",
        "\n",
        "plt.imshow(sample_output[idx].squeeze().cpu())\n",
        "plt.show()\n",
        "plt.imshow(sample_target[idx].squeeze().permute(1,2,0))\n",
        "plt.show()\n",
        "plt.imshow(sample_input[idx].squeeze().permute(1,2,0))"
      ],
      "metadata": {
        "id": "NWKUPV0ReG6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '../')"
      ],
      "metadata": {
        "id": "Up4GPRiXkOP3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}