{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as N\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root= '../pytorch-basics/datasets/mnist/train',\n",
    "    train= True,\n",
    "    download= True,\n",
    "    transform= ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root= '../pytorch-basics/datasets/mnist/test',\n",
    "    train= False,\n",
    "    download= True,\n",
    "    transform= ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size= batch_size, shuffle= True)\n",
    "test_dataloader = DataLoader(test_data, batch_size= batch_size, shuffle= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = N.Sequential(\n",
    "            N.Conv2d(in_channels= 1, out_channels= 16, kernel_size= 3, stride= 1, padding= 1),\n",
    "            N.Tanh(),\n",
    "            N.MaxPool2d(kernel_size= 2, stride= 2),\n",
    "\n",
    "            N.Conv2d(in_channels= 16, out_channels= 32, kernel_size= 3, stride= 1, padding= 1),\n",
    "            N.Tanh(),\n",
    "            N.MaxPool2d(kernel_size= 2, stride= 2),\n",
    "\n",
    "            N.Flatten(),\n",
    "\n",
    "            N.Linear(in_features= 32*7*7, out_features= 500),\n",
    "            N.Tanh(),\n",
    "            \n",
    "            N.Linear(in_features= 500, out_features= 100),\n",
    "            N.Tanh(),\n",
    "            \n",
    "            N.Linear(in_features= 100, out_features= 50),\n",
    "            N.Tanh(),\n",
    "            \n",
    "            N.Linear(in_features= 50, out_features= 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Trainable\n",
       "============================================================================================================================================\n",
       "Sequential (Sequential)                  [32, 1, 28, 28]           [32, 10]                  --                        True\n",
       "├─Conv2d (0)                             [32, 1, 28, 28]           [32, 16, 28, 28]          160                       True\n",
       "├─Tanh (1)                               [32, 16, 28, 28]          [32, 16, 28, 28]          --                        --\n",
       "├─MaxPool2d (2)                          [32, 16, 28, 28]          [32, 16, 14, 14]          --                        --\n",
       "├─Conv2d (3)                             [32, 16, 14, 14]          [32, 32, 14, 14]          4,640                     True\n",
       "├─Tanh (4)                               [32, 32, 14, 14]          [32, 32, 14, 14]          --                        --\n",
       "├─MaxPool2d (5)                          [32, 32, 14, 14]          [32, 32, 7, 7]            --                        --\n",
       "├─Flatten (6)                            [32, 32, 7, 7]            [32, 1568]                --                        --\n",
       "├─Linear (7)                             [32, 1568]                [32, 500]                 784,500                   True\n",
       "├─Tanh (8)                               [32, 500]                 [32, 500]                 --                        --\n",
       "├─Linear (9)                             [32, 500]                 [32, 100]                 50,100                    True\n",
       "├─Tanh (10)                              [32, 100]                 [32, 100]                 --                        --\n",
       "├─Linear (11)                            [32, 100]                 [32, 50]                  5,050                     True\n",
       "├─Tanh (12)                              [32, 50]                  [32, 50]                  --                        --\n",
       "├─Linear (13)                            [32, 50]                  [32, 10]                  510                       True\n",
       "============================================================================================================================================\n",
       "Total params: 844,960\n",
       "Trainable params: 844,960\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 60.00\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 4.99\n",
       "Params size (MB): 3.38\n",
       "Estimated Total Size (MB): 8.47\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size= (batch_size, 1, 28, 28), col_names=['input_size', 'output_size', 'num_params', 'trainable'], \n",
    "\n",
    "        row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_fn = N.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "accuracy_fn = Accuracy(task= 'multiclass', num_classes= 10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch: 1\n",
      "~~~~~~~~~~~\n",
      "Batch: 0 Loss:2.29484\n",
      "Batch: 500 Loss:0.19320\n",
      "Batch: 1000 Loss:0.04784\n",
      "Batch: 1500 Loss:0.22656\n",
      "Train loss: 0.19112 Test loss: 0.07889 Test acc: 97.67%\n",
      "\n",
      "Starting epoch: 2\n",
      "~~~~~~~~~~~\n",
      "Batch: 0 Loss:0.04243\n",
      "Batch: 500 Loss:0.13195\n",
      "Batch: 1000 Loss:0.01587\n",
      "Batch: 1500 Loss:0.00416\n",
      "Train loss: 0.06111 Test loss: 0.06028 Test acc: 98.26%\n",
      "\n",
      "Starting epoch: 3\n",
      "~~~~~~~~~~~\n",
      "Batch: 0 Loss:0.01905\n",
      "Batch: 500 Loss:0.01242\n",
      "Batch: 1000 Loss:0.00604\n",
      "Batch: 1500 Loss:0.00730\n",
      "Train loss: 0.04295 Test loss: 0.04545 Test acc: 98.45%\n",
      "\n",
      "Starting epoch: 4\n",
      "~~~~~~~~~~~\n",
      "Batch: 0 Loss:0.01236\n",
      "Batch: 500 Loss:0.02852\n",
      "Batch: 1000 Loss:0.00185\n",
      "Batch: 1500 Loss:0.00985\n",
      "Train loss: 0.03309 Test loss: 0.04948 Test acc: 98.41%\n",
      "\n",
      "Starting epoch: 5\n",
      "~~~~~~~~~~~\n",
      "Batch: 0 Loss:0.05067\n",
      "Batch: 500 Loss:0.00071\n",
      "Batch: 1000 Loss:0.03898\n",
      "Batch: 1500 Loss:0.00204\n",
      "Train loss: 0.02870 Test loss: 0.04317 Test acc: 98.69%\n"
     ]
    }
   ],
   "source": [
    "for _ in range(epochs):\n",
    "    train_loss = 0\n",
    "    print(f\"\\nStarting epoch: {_ + 1}\\n~~~~~~~~~~~\")\n",
    "    for index, (input, target) in enumerate(train_dataloader):\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "        model.train()\n",
    "        output = model(input)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if(index % 500 == 0):\n",
    "            print(f\"Batch: {index} Loss:{loss:0.5f}\")\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for test_input, test_target in test_dataloader:\n",
    "            test_input, test_target = test_input.cuda(), test_target.cuda()\n",
    "\n",
    "            test_pred = model(test_input)\n",
    "            test_loss += loss_fn(test_pred, test_target)\n",
    "            test_acc += accuracy_fn(test_target, test_pred.argmax(dim= 1))\n",
    "        \n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:0.5f} Test loss: {test_loss:0.5f} Test acc: {test_acc*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
